---
source: Rmd
title: "Data Wrangling"
teaching: 50
exercises: 10
questions:
- "What is data wrangling?"
- "How do we wrangle data in R?"
objectives:
- "Use the **tidyverse** package to build your first data pipeline"
- "Perform basic data manipulation tasks"
- "Inspect and summarise data"
keypoints:
- "The process of transforming data from a raw to more usable format"
- "Most easily using packages from the **tidyverse**"
---

## Data wrangling with dplyr

Data wrangling is the process of reshaping data from its raw format, inta a format that is suitable for analysis. A typical goal is to make sure our data is in a "tidy" format. To [quote](https://blog.rstudio.org/2014/07/22/introducing-tidyr/) one of R's current chief architects (Hadley Wickham), tidy data is shaped such that:

> Each column is a variable.
> Each row is an observation.

The `dplyr` package provides useful _grammar_ for simplifying data manipulation. It is not needed but makes manipulation verbose and intuitive and is highly recommended. Let's load of the package along with the rest of the tidyverse if not already done. And we can read in the synthetic cohort.

```{r}
library(tidyverse)
df <- read_csv("./data/synthetic_data_clean.csv")
```

We can inspect the data again.

```{r}
glimpse(df)
```

Using our synthetic cohort, let's _filter_ the demographic data by row.

```{r}
filter(df, height >= 1.8)
```

This _filters_ rows from the `df` data frame where `height` is greater than or equal to `1.8` m.

> **TIP:** Comparisons in R: Most of these are obvious `>` (greater than), `>=` (greater than or equal to), and similarly for `<` and `<=`.  The `!=` operator means 'not equal to'. But when we want to check if something _is_ equal to something else we _must_ use `==`. Why? Because although R prefers you to use `<-` when you name things, most programming languages use `=`, and even R expects you to use `=` when you pass values to functions. So, for a function such as `mean(x)` we are normally lazy when we write `mean(hrate)`. We should write `mean(x = hrate)`, because _inside_ the function all the work is done with the variable `x`. When we write `mean(x = hrate)` we explicitly telling R that we want it to use `hrate` in place of `x`. This is a very long winded way of saying that when you want to _test_ if one thing is equal to another then you need a different way of writing this, hence `==`.

Filter **always** acts on rows, and will throw away any data that doesn't meet your request.

```{r}
include_graphics("./img/filter.png")
```

A similar function called `select` acts over columns. Just want the `sex` colum?

```{r}
select(df, sex)
```

```{r}
include_graphics("./img/select.png")
```

So `filter` chooses rows, and `select` chooses columns.

Now here comes the _proper_ magic. What if you want to both filter and select?

```{r}
df %>%
  filter(height >= 1.8) %>%
  select(sex)
```

The `%>%` operator is called a **pipe**, and it (surprise, surprise) _pipes_ data from one command to the next. So in plain English, the above line takes the data frame `df` and pipes it into the _filter_ function, removing all patients under `1.8` m. It then pipes the filtered data into the `select` function where only the `sex` column is retained.

The benefit of writing code like this, is that you start with your data at the top, and then each line is a single function that performs an action. The data is processed one step at a time at the bottom you get your tidy data. This is the very start of a data pipeline.

> **TIP:** The order matters in a pipe! If we were to use the `select` function first, then the `filter` function would not have a `height` column to filter on.).

Next, you can continue to expand your data pipeline by piping your data into another function. We might want to summarise the data. By appending the pipeline with the `group_by` and `tally` functions we can tabulate the results.

```{r}
df %>%
  filter(height >= 1.8) %>%
  select(sex) %>%
  group_by(sex) %>%
  tally()
```

There are a small number of 'verbs' (functions) in the dplyr package that when combined allow you to complete a large number of useful data maniputations. In addition to `select`, and `filter`, you will want you to learn:

1. `arrange` - orders data using a named column
2. `group_by`- sets a column to be a grouping variable
3. `summarise`- summarises data over a grouping variable
4. `mutate` - add a new column to the data

Armed with only these 6 functions, you can accomplish a huge amount that would be tiresome and frustrating in excel.

### Arrange

```{r}
df %>%
  select(height, weight, sex) %>%
  arrange(height)
```

```{r}
include_graphics("./img/arrange.png")
```

Here we see an example where we select the height, weight and sex columns, and then arrange the data by the height column.

### Group By and Summarise

We now see an example of `group_by` and `summarise` being used together. The result is to apply the function `mean` to each group, and summarise the results. The `na.rm = TRUE` has to be added if there are missing values are present in the data. We don't have any here, but it's good to remember for your own data.

```{r}
df %>%
  group_by(sex) %>%
  summarise(average_height = mean(height, na.rm = TRUE))
```

the group by function on it's own doesn't really achieve much. It creates a grouping so that a summary function can act over that grouping.

### Mutate

We might be interested in computing the BMI for a patient. We can do this easily by adding a new column with the `mutate` verb.

```{r}
df %>%
  mutate(bmi = weight / (height/100)^2)
```

We now create a new column called `bmi`.

```{r}
include_graphics("./img/mutate.png")
```

Let's combine a few of these functions to return only the data we want to see.

```{r}
df %>%
  mutate(bmi = weight / (height)^2) %>%
  select(weight, height, bmi) %>%
  arrange(desc(bmi))
```

There are many other functions in dplyr that can help with easy data maniputation. Have a look at the cheatsheet for more details.

## Data Cleaning

We will now go through some common data cleaning tasks. It is better to try and do these in R, rather than adjust the underlying data in excel if possible. Some tasks are going to have to be done in excel, but the more you can do this with written instructions (and hence have written documentation) the better.

```{r}
names(df)
```

Some of these variable names are too vague for my liking.
- chemo: active or historical?
- na: too similar to the R concept of "missing" i.e. NA
- system: a little ambiguous

We're using the `rename` function from the dplyr package, and then 'overwriting' our existing data with the renamed data. We use the format of `rename(new_name = old_name)`. Note that we are using single `=` and not double `==` because we are assigning something, not checking for equality.

```{r, eval = FALSE}
df <- df %>%
  rename(new_name = old_name)
```

```{r}
df <- df %>%
  rename(chemo_6_months = chemo,
         sodium = na,
         organ_system = system)
```

### Exercise

Use the functions you have just learnt to:
- Find the mean apache score for survivors and non-survivors
- Create a new column with the highest temp from temp_c and temp_nc

<a name="stringr"></a>

## Wrangling strings

### Extract numbers

The `parse_number()` function is useful when numbers have been embedded inside a character vector. We can see this in our data in the `lactate_abg` column, where the units of measure (mmol/L) have crept into the column.

## Parsing Dates

Let's create two new columns that show us the length of stay for a patient, and their age on admission.

Dates can be extremely fiddly, but fortunately, tidyverse comes to our rescue. We will need only the `arrival_dttm` and `discharge_dttm` columns to do what we want.

```{r}
df <- df %>%
  mutate(los = interval(arrival_dttm, discharge_dttm) / days(1))

df %>%
  select(los)
```

Working with dates can be extremely difficult. Let's practice a few simple and common tasks.

### Exercise

Use the functions you have just learnt to:
- Find the mean los for survivors and non-survivors
- Calculate the age on arrival for these patients

## Pivoting Data

Right now we have data arranged in 1 row per admission (1 row per patient since there are no repeat admissions). This is normally called the "wide" format. We might want this in a slightly different format (the "long" or "tall" format) to answer a different type of question. This process is known as pivoting.

In our data, the lactate was recorded at hours 1, 6 and 12. Really, this data needs to be stacked for easy analysis. We can achieve this with the `pivot_longer()` function

```{r}
df_long <- df %>%
  pivot_longer(
    cols = c("lactate_1hr", "lactate_6hr", "lactate_12hr"),
    names_to = "lactate_time",
    values_to = "lactate_value") %>%
  select(id, lactate_time, lactate_value)
```

To showcase why this was useful, we can draw a spagetti plot and view how the lactate changes over time. Don't worry about the plotting syntax for now, this will be covered in another talk.

```{r, include = FALSE}
df_long %>%
  filter(id %in% sample(df_long$id, 100, replace = FALSE)) %>%
  mutate(lactate_time = factor(lactate_time, levels = c("lactate_1hr", "lactate_6hr", "lactate_12hr"), ordered = TRUE)) %>%
  ggplot(aes(group = id, x = lactate_time, y = lactate_value)) + geom_line(alpha = 0.2) +
  theme_classic() +
  ylab("Lactate mmol/L") +
  xlab("Time Lactate Measured") +
  ggtitle("Serial Lactate Measurements")
```

  
